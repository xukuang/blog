---
layout: post
title: "离散型随机变量的常用统计指标"
date: 2016-04-06 22:25:50
categories: [学习篇]
tags: [统计]
---
## 期望

$$E[X] = \sum_{i=1}^n x_i$$

期望存在一下特性:

1.$$E[aX + bY] = aE[X] + bE(Y)$$
2. 一般情况下，$$E[X Y] \neq E[X]E(Y)$$；当X和Y相互独立时，才有$$E[X Y] = E[X]E(Y)$$<!--more-->

## 方差
方差描述的是随机变量的离散程度，也就是该变量离其期望值的距离。

$$Var(X) = E[(X -E[X])^2] = E[X^{2} - 2X E[X] + (E[X])^{2}] = E[X^{2}] - (E[X])^{2}$$
此外，方差还可以看作是随机变量和自身的协方差$$Var(X) = Cov(X, X)$$

## 标准差
标准差是一组数值自平均值分散开来的程度的一种测量观念。
总体的标准差$$SD = \sqrt{\frac{Var(x)}{N}}$$，样本的标准差$$SD = \sqrt{\frac{Var(x)}{N - 1}}$$

## 标准误
标准误差针对样本统计量而言，是某个样本统计量的标准差。当谈及标准误差时，一般须指明对应的样本统计量才有意义。以下以样本均值（样本均值是一种样本统计量）作为例子。于是，假设可以从总体中随机选取无限的大小相同的样本，那每个样本都可以有一个样本均值。依此法可以到一个由无限多样本均值组成的总体，该总体的标准差即为标准误差。

$$SE = \frac{SD}{\sqrt{N}}$$

## 协方差
协方差用于衡量两个变量的总体误差。而方差是协方差的一种特殊情况，即当两个变量是相同的情况。

$$Cov(X, Y) = E((X - E[X])(Y - E(Y)) = E[XY] - E[X] E[Y]$$。

协方差表示的是两个变量的总体的误差，这与只表示一个变量误差的方差不同。 如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值。如果两个变量的变化趋势相反，即其中一个大于自身的期望值，另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。如果X与Y是统计独立的，那么二者之间的协方差就是0，但是反过来并不成立，即如果X与Y的协方差为0，二者并不一定是统计独立的。

## 协方差的相关性η(线性相关)

 $$\eta =  \frac{cov(X, Y)}{\sqrt{var(X) \cdot var(Y)}}$$

协方差的相关性η更准确地说是线性相关的相关系数r，是一个衡量线性独立的无量纲数，其取值在[－1,+1]之间。相关性η = 1时称为“完全线性相关”(相关性η = -1时称为“完全线性负相关”)，此时将$Y_{i}$对$X_{i}$作Y-X散点图，将得到一组精确排列在直线上的点；相关性数值介于－1到1之间时，其绝对值越接近1表明线性相关性越好，作散点图得到的点的排布越接近一条直线。相关性为0(因而协方差也为0)的两个随机变量又被称为是不相关的，或者更准确地说叫作“线性无关”、“线性不相关”，这仅仅表明X 与Y两随机变量之间没有线性相关性，并非表示它们之间一定没有任何内在的（非线性）函数关系，和前面所说的“X、Y二者并不一定是统计独立的”说法一致。
\------

**本篇文章整理自维基百科。**